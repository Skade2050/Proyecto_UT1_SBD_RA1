# ğŸ“š Mini-pipeline de libros (Goodreads + Google Books)

Este repositorio implementa un mini-pipeline de extracciÃ³n â†’ enriquecimiento â†’ integraciÃ³n para un conjunto pequeÃ±o de libros.

El objetivo es obtener datos desde Goodreads (scraping), enriquecerlos usando la API de Google Books y consolidar ambas fuentes en un modelo canÃ³nico, asegurando trazabilidad, normalizaciÃ³n y mÃ©tricas de calidad.

## ğŸ“ Estructura del repositorio

```
books-pipeline/
â”œâ”€â”€ landing/
â”‚   â”œâ”€â”€ goodreads_books.json
â”‚   â””â”€â”€ googlebooks_books.csv
â”œâ”€â”€ standard/
â”‚   â”œâ”€â”€ dim_book.parquet
â”‚   â””â”€â”€ book_source_detail.parquet
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ quality_metrics.json
â”‚   â””â”€â”€ schema.md
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scrape_goodreads.py
â”‚   â”œâ”€â”€ enrich_googlebooks.py
â”‚   â”œâ”€â”€ integrate_pipeline.py
â”‚   â”œâ”€â”€ utils_isbn.py
â”‚   â””â”€â”€ utils_quality.py
â”œâ”€â”€ .env.example
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ”§ Requisitos

- Python 3.10+
- ConexiÃ³n a Internet
- Dependencias:
  - requests, beautifulsoup4, lxml
  - pandas, numpy, pyarrow
  - python-dotenv (opcional)

InstalaciÃ³n:

```bash
pip install -r requirements.txt
```

## ğŸ•¸ï¸ Scraping de Goodreads

```bash
python src/scrape_goodreads.py
```

### QuÃ© hace

- Busca â€œdata scienceâ€ en Goodreads.
- Extrae tÃ­tulo, autores, rating, pÃ¡ginas, fecha de publicaciÃ³n y mÃ¡s.
- Usa estos selectores:

```
h1[data-testid='bookTitle']
span[data-testid='authorName'] a
span[data-testid='ratingValue']
span[data-testid='ratingsCount']
p[data-testid='pagesFormat']
p[data-testid='publicationInfo']
```

### Ã‰tica del scraping

- Pausas de 0.5â€“1.5s
- User-Agent realista
- Sin acciones agresivas

Salida:

```
landing/goodreads_books.json
```

## ğŸ“š Enriquecimiento con Google Books

```bash
python src/enrich_googlebooks.py
```

- Construye queries usando isbn13 â†’ isbn10 â†’ tÃ­tulo+autor.
- Llama a la API de Google Books.
- Extrae tÃ­tulo, autores, editorial, fecha, idioma, categorÃ­as, precio, ISBNs.

Configurar `.env` opcional:

```
GOOGLE_BOOKS_API_KEY=TU_API_KEY
```

Salida:

```
landing/googlebooks_books.csv
```

## ğŸ”„ IntegraciÃ³n + NormalizaciÃ³n + DeduplicaciÃ³n

```bash
python src/integrate_pipeline.py
```

### NormalizaciÃ³n

- TÃ­tulo normalizado
- Idioma BCP-47 aproximado
- Moneda ISO-4217
- Fechas ISO-8601
- ISBN como texto

### Clave canÃ³nica (`book_id`)

```
Si existe isbn13 vÃ¡lido â†’ book_id = isbn13
Si no â†’ tÃ­tulo_normalizado + autor_principal + aÃ±o
```

### DeduplicaciÃ³n

Prioridad:

1. google_books
2. goodreads

Reglas:

- Se escoge el registro con mÃ¡s prioridad por fuente.
- Se genera `book_source_detail` con provenance.

## ğŸ“¦ Artefactos generados

### standard/

| Archivo | DescripciÃ³n |
|--------|-------------|
| dim_book.parquet | Tabla final, 1 fila por libro |
| book_source_detail.parquet | Detalle por fuente y registro original |

### docs/

| Archivo | DescripciÃ³n |
|--------|-------------|
| quality_metrics.json | MÃ©tricas de calidad |
| schema.md | DocumentaciÃ³n del modelo |

## ğŸ“Š MÃ©tricas de calidad (ejemplo real)

```json
{
  "total_registros": 24,
  "total_goodreads": 12,
  "total_google_books": 12,
  "porcentaje_valid_isbn13": 0.0,
  "porcentaje_valid_fecha_publicacion": 50.0,
  "porcentaje_valid_idioma": 50.0,
  "porcentaje_valid_moneda": 29.17,
  "claves_candidatas_duplicadas": 0
}
```

## ğŸ›¡ï¸ Aserciones de calidad

El pipeline falla si:

- book_id no es Ãºnico  
- <80% de tÃ­tulos  
- aÃ±os sospechosos (<1800)  
- precios â‰¤ 0  

## â–¶ï¸ EjecuciÃ³n completa

```bash
python src/scrape_goodreads.py
python src/enrich_googlebooks.py
python src/integrate_pipeline.py
```

## âœ”ï¸ Estado final del proyecto

- Pipeline funcional completo  
- NormalizaciÃ³n y deduplicaciÃ³n correctas  
- Provenance detallado  
- MÃ©tricas y aserciones  
- Artefactos en Parquet + documentaciÃ³n  
